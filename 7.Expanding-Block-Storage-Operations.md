```text
作者：李晓辉

联系方式：

1. 微信：Lxh_Chat

2. 邮箱：939958092@qq.com
```

# 配置RBD镜像

## RBD镜像

可以将 RBD 镜像从一个红帽 Ceph 存储集群自动复制到另一个远程集群。这种机制会利用异步方式，通过网络来镜像来源（主要）RBD 镜像和目标（次要）RBD 镜像。如果包含主要 RBD 镜像的集群变得不可用，则可以从远程集群故障转移到次要 RBD 镜像，并重启使用它的应用。

从来源 RBD 镜像故障转移到镜像的 RBD 镜像时，您必须*降级*来源 RBD 镜像并*升级*目标 RBD 镜像。降级的镜像会变为锁定且不可用的状态。升级的镜像会变为可用状态，可以在读写模式中访问。

RBD 镜像功能要求 *rbd-mirror* 守护进程。*rbd-mirror* 守护进程从远程对等集群拉取镜像更新，并将其应用到本地集群镜像。

## 支持的镜像配置

RBD镜像支持两种配置:

1. 单向镜像或active-passive 

2. 双向镜像或active-active

### 单向镜像或主动-被动

在单向模式中，一个集群的 RBD 镜像可以读写模式访问，远程集群中包含镜像。镜像代理在远程集群上运行。这种模式可以支持配置多个次要集群。

![](https://gitee.com/cnlxh/cl260/raw/master/images/block/RBD_mirror_one-way_diagram.svg)

### 双向镜像或主动-主动

在双向模式中，Ceph 使来源与目标对（主要与次要）保持同步。此模式仅允许在两个集群之间进行复制，您也必须在每个集群上配置镜像代理。

![](https://gitee.com/cnlxh/cl260/raw/master/images/block/RBD_mirror_two-way_diagram.svg)

## 受支持的镜像模式

RBD镜像支持两种模式: <mark>pool模式和image模式</mark>

### pool模式

在池模式下，Ceph 自动为被镜像池中创建的每一个 RBD 镜像启用镜像功能。当在来源集群上的池中创建镜像时，<mark>Ceph 会在远程集群中自动创建目标镜像</mark>

### image模式

在镜像模式中，可以选择性地为被镜像池中的个别 RBD 镜像启用镜像功能。在这种模式中，您必须显式选择要在两个集群之间复制的 RBD 镜像

## RBD 镜像的镜像状态

### 基于日志的镜像

此模式通过 RBD 日志镜像功能来确保两个红帽 Ceph 存储集群之间的时间点和崩溃一致性复制。对 RBD 镜像的每一次写入首先要记录到相关日志中，然后再修改实际镜像。远程集群从此日志中读取，并将更新内容重播到其镜像的本地副本。

### 基于快照的镜像

基于快照的镜像使用<mark>定期调度或手动创建的 RBD 镜像快照</mark>，在两个红帽 Ceph 存储集群之间复制崩溃一致性 RBD 镜像。远程集群确定两个镜像快照之间的数据或元数据更新，并将增量复制到镜像的本地副本。在故障转移场景中，<mark>必须先同步两个快照之间的完整增量</mark>，然后才能使用。任何部分应用的增量集都会在故障转移时回滚。

# 实践：配置RBD Mirror

<mark>将serverc上rbdtest池中的lxhrbdname镜像和serverf的rbdtest池中的同名镜像保持同步</mark>

## 创建RBD源池

创建一个名为rbdtest的池，稍后将会和第二个集群进行池同步

```bash
[root@serverc ~]# ceph osd pool create rbdtest
pool 'rbdtest' created
[root@serverc ~]# ceph osd pool application enable rbdtest rbd
enabled application 'rbd' on pool 'rbdtest'
[root@serverc ~]# rbd pool init -p rbdtest
```

## 创建备份集群目标RBD池

请参考ceph部署完成第二套集群部署

创建第二套集群中同名池为rbdtest的rbd池

```bash
[root@serverf ~]# ceph osd pool create rbdtest
pool 'rbdtest' created
[root@serverf ~]# ceph osd pool application enable rbdtest rbd
enabled application 'rbd' on pool 'rbdtest'
[root@server ~]# rbd pool init -p rbdtest
```

## 创建源镜像

在源集群的rbdtest池中创建一个名为lxhrbdname的镜像，大小为1000M，启用 `exclusive-lock` 和 `journaling` RBD 镜像功能

注意到`mirroring state: disabled`

```bash
[root@serverc ~]# rbd create --size 1000M -p rbdtest lxhrbdname \
--image-feature=exclusive-lock,journaling
[root@serverc ~]# rbd info -p rbdtest lxhrbdname
rbd image 'lxhrbdname':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: dbc45a6069eb
        block_name_prefix: rbd_data.dbc45a6069eb
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Wed Aug  7 05:22:20 2024
        access_timestamp: Wed Aug  7 05:22:20 2024
        modify_timestamp: Wed Aug  7 05:22:20 2024
        journal: dbc45a6069eb
        mirroring state: disabled
```

## 启用池模式mirror

在源集群中的rbdtest池上启用mirror同步，注意info中的同步信息

注意到`mirroring state: enabled`

```bash
[root@serverc ~]# rbd mirror pool enable rbdtest pool
[root@serverc ~]# rbd info -p rbdtest lxhrbdname
rbd image 'lxhrbdname':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: dbc45a6069eb
        block_name_prefix: rbd_data.dbc45a6069eb
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Wed Aug  7 05:22:20 2024
        access_timestamp: Wed Aug  7 05:22:20 2024
        modify_timestamp: Wed Aug  7 05:22:20 2024
        journal: dbc45a6069eb
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: d91f0fe4-4f27-4df2-88b1-38e3ffe9b177
        mirroring primary: true
```

## 准备源同步token

在源集群中生成同步的key，将源集群的站点命名为site1，保存好，稍后用于复制到第二套集群

```bash
[root@serverc ~]# rbd mirror pool peer bootstrap create \
--site-name site1 rbdtest > site1.key
[root@serverc ~]# cat site1.key
eyJmc2lkIjoiMmFlNmQwNWEtMjI5YS0xMWVjLTky...
```

```bash
[root@serverc ~]# scp -p site1.key root@serverf:/root
site1.key                   100%  253   142.4KB/s   00:00
```

目标集群部署rbd-mirror进程

```bash
[root@serverf ~]# ceph orch apply rbd-mirror --placement=serverf.lab.example.com
Scheduled rbd-mirror update...
[root@serverf ~]# ceph orch ps | grep mirror
rbd-mirror.serverf.veenfh           serverf.lab.example.com  running (5s)  1s ago     5s   -              16.2.0-117.el8cp  2142b60d7974  c9b6b8ff89e8
```

## 导入源集群token密钥

导入源集群的key，并命名本地集群为backupceph，从info信息中看到mirroring primary: false

**忽略包含以下文本的已知错误：auth: unable to find a keyring on …**

<mark>import这一步执行成功后，在备份集群就已经可以看到源镜像了</mark>

```bash
[root@serverf ~]# rbd mirror pool peer bootstrap import \
--site-name backupceph --direction rx-only rbdtest /root/site1.key
[root@serverf ~]#
[root@cephbackup ~]# rbd -p rbdtest ls
lxhrbdname
[root@serverf ~]# rbd -p rbdtest info lxhrbdname
rbd image 'lxhrbdname':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: 37a88b1c5510
        block_name_prefix: rbd_data.37a88b1c5510
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Sun Sep 18 15:18:32 2022
        access_timestamp: Sun Sep 18 15:18:32 2022
        modify_timestamp: Sun Sep 18 15:18:32 2022
        journal: 37a88b1c5510
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: 165a0e83-8e8b-43cb-8d93-6b1812e3c58c
        mirroring primary: false
```

## 查询同步状态

在两台机器上，分别执行这个命令，可以看到两个站点的信息

```bash
[root@serverf ~]# rbd mirror pool info rbdtest
Mode: pool
Site Name: backupceph

Peer Sites:

UUID: 6b9fb207-4555-4637-8954-f637453081c9
Name: site1
Direction: rx-only
Client: client.rbd-mirror-peer
```

在备份的集群中，查询守护进程和镜像的健康状态

```bash
[root@serverf ~]# rbd mirror pool status -p rbdtest
health: OK
daemon health: OK
image health: OK
images: 1 total
    1 replaying
```

再次到源集群去看看镜像状态

```bash
[root@serverc ~]# rbd -p rbdtest info lxhrbdname
rbd image 'lxhrbdname':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: d3d46acc6e3f
        block_name_prefix: rbd_data.d3d46acc6e3f
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Fri Sep  8 12:12:16 2023
        access_timestamp: Fri Sep  8 12:12:16 2023
        modify_timestamp: Fri Sep  8 12:12:16 2023
        journal: d3d46acc6e3f
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: 57379079-48cc-4091-b08c-01e087562d9b
        mirroring primary: true
```

再次到源集群去看看池的同步状态

```bash
[root@serverc ~]# rbd mirror pool info rbdtest
Mode: pool
Site Name: site1

Peer Sites:

UUID: e060d31c-94c7-495d-8612-4ae890e0a4e7
Name: backupceph
Mirror UUID: eac9e8a9-b13c-46f3-9997-6c22555b77b7
Direction: tx-only
```

## 创建新镜像测试是否同步

重新在源集群的池中创建一个镜像，稍后再去第二套集群看看是否同步成功

```bash
[root@serverc ~]# rbd create --size 1000M -p rbdtest image2 \
> --image-feature=exclusive-lock,journaling
[root@serverc ~]# rbd info image2 -p rbdtest
rbd image 'image2':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: d420d153d504
        block_name_prefix: rbd_data.d420d153d504
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Fri Sep  8 12:23:23 2023
        access_timestamp: Fri Sep  8 12:23:23 2023
        modify_timestamp: Fri Sep  8 12:23:23 2023
        journal: d420d153d504
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: 644301a8-22b5-46e8-9027-103ecfbc7f74
        mirroring primary: true
```

在第二套集群中查看，发现已经同步成功

```bash
[root@serverf ~]# rbd -p rbdtest ls
image2
lxhrbdname
[root@serverf ~]# rbd -p rbdtest info image2
rbd image 'image2':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: 8575f69a1f
        block_name_prefix: rbd_data.8575f69a1f
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Fri Sep  8 12:23:25 2023
        access_timestamp: Fri Sep  8 12:23:25 2023
        modify_timestamp: Fri Sep  8 12:23:25 2023
        journal: 8575f69a1f
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: 644301a8-22b5-46e8-9027-103ecfbc7f74
        mirroring primary: false
```

## 测试删除镜像的同步

这个删除，<mark>只能从源集群删除</mark>

```bash
[root@serverc ~]# rbd ls -p rbdtest
image2
lxhrbdname
[root@serverc ~]# rbd rm lxhrbdname -p rbdtest
Removing image: 100% complete...done.
[root@serverc ~]# rbd ls -p rbdtest
image2
```

到备份集群看看删除成功没

```bash
[root@serverf ~]# rbd ls -p rbdtest
image2
```

一些额外的mirror命令：

如果两个peer集群之间的状态不一致，rbd-mirror守护进程不会尝试mirror不一致的映像，<mark>在备份集群上</mark>使用rbd mirror image resync重新同步映像

```bash
[root@serverf ~]# rbd mirror image resync rbdtest/image2
Flagged image for resync from primary
```

使用rbd mirror image enable或rbd mirror image disable在两个对端存储集群上的整个池image模式中启用或禁用mirroring模式

```bash
rbd mirror image enable mypool/myimage
rbd mirror image disable mypool/myimage
```

使用基于快照的镜像，通过禁用镜像和启用快照，将基于日志的镜像转换为基于快照的镜像

```bash
rbd mirror image disable mypool/myimage
rbd mirror image enable mypool/myimage snapshot
```

## 故障转移过程

如果主要 RBD 镜像变得不可用，您可按照步骤启动对次要 RBD 镜像的访问：

- 停止访问主要 RBD 镜像。也就是说，停止正在使用该镜像的所有应用和虚拟机。

- 使用 `rbd mirror image demote rbdtest/image2` 命令来降级主要 RBD 镜像。

- 使用 `rbd mirror image promote rbdtest/image2` 命令来升级次要 RBD 镜像。

- 恢复访问 RBD 镜像。重新启动应用和虚拟机。

在非有序关机后发生故障转移时，您必须从备份存储集群中的 Ceph 监控器节点升级非主要镜像。使用 `--force` 选项，因为降级无法传播到主要存储集群

### 降级集群镜像

降级操作必须是源集群执行，除非源集群不存在，可以尝试用--force

我们发现降级后，serverc就不再是primary了

```bash
[root@serverc ~]# rbd info rbdtest/image2
rbd image 'image2':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: d420d153d504
        block_name_prefix: rbd_data.d420d153d504
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Fri Sep  8 12:23:23 2023
        access_timestamp: Fri Sep  8 12:23:23 2023
        modify_timestamp: Fri Sep  8 12:23:23 2023
        journal: d420d153d504
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: 644301a8-22b5-46e8-9027-103ecfbc7f74
        mirroring primary: true

[root@serverc ~]# rbd mirror image demote rbdtest/image2
Image demoted to non-primary

[root@serverc ~]# rbd info rbdtest/image2
rbd image 'image2':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: d420d153d504
        block_name_prefix: rbd_data.d420d153d504
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Fri Sep  8 12:23:23 2023
        access_timestamp: Fri Sep  8 12:23:23 2023
        modify_timestamp: Fri Sep  8 12:23:23 2023
        journal: d420d153d504
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: 644301a8-22b5-46e8-9027-103ecfbc7f74
        mirroring primary: false
```

### 提升集群镜像

在备份集群提升了镜像后，serverf变成了primary

```bash
[root@serverf ~]# rbd info rbdtest/image2
rbd image 'image2':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: 85757ad71c90
        block_name_prefix: rbd_data.85757ad71c90
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Fri Sep  8 12:32:14 2023
        access_timestamp: Fri Sep  8 12:32:14 2023
        modify_timestamp: Fri Sep  8 12:32:14 2023
        journal: 85757ad71c90
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: 644301a8-22b5-46e8-9027-103ecfbc7f74
        mirroring primary: false
[root@serverf ~]# rbd mirror image promote rbdtest/image2
Image promoted to primary
[root@serverf ~]# rbd info rbdtest/image2
rbd image 'image2':
        size 1000 MiB in 250 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: 85757ad71c90
        block_name_prefix: rbd_data.85757ad71c90
        format: 2
        features: exclusive-lock, journaling
        op_features:
        flags:
        create_timestamp: Fri Sep  8 12:32:14 2023
        access_timestamp: Fri Sep  8 12:32:14 2023
        modify_timestamp: Fri Sep  8 12:32:14 2023
        journal: 85757ad71c90
        mirroring state: enabled
        mirroring mode: journal
        mirroring global id: 644301a8-22b5-46e8-9027-103ecfbc7f74
        mirroring primary: true
```

# 实践：提供iSCSI

部署红帽 Ceph 存储 iSCSI 网关前，需满足下列前提条件：

- 安装运行有红帽企业 Linux 8.3 或更新版本的 iSCSI 网关节点。

- 拥有运行红帽 Ceph 存储 5 或更高版本的运行集群。

- iSCSI 网关节点上要有 90MiB 的 RAM 用于作为目标公开的每个 RBD 镜像。

- 在每个 Ceph iSCSI 节点的防火墙上打开 TCP 端口 3260 和 5000。

- 创建新的 RADOS 块设备或使用现有可用设备。

## 创建iSCSI池

创建一个iSCSI存储池，用于存放iSCSI的存储卷

```bash
[root@serverc ~]# ceph osd pool create iscsipool
pool 'iscsipool' created
[root@serverc ~]# ceph osd pool application enable iscsipool rbd
enabled application 'rbd' on pool 'iscsipool'
[root@serverc ~]# rbd pool init -p iscsipool
```

## 部署iSCSI进程

iSCSI部署格式为：

```text
ceph orch apply iscsi <pool> <api_user> <api_password> [<trusted_ip_list>]
```

将iSCSI进程部署到相应机器上，api账号密码为admin

```bash
[root@serverc ~]# ceph orch apply iscsi iscsipool \
admin admin 172.25.250.12 --placement='serverc.lab.example.com'
Scheduled iscsi.iscsipool update...

[root@serverc ~]# ceph orch ps | grep iscsi
iscsi.iscsipool.serverc.ydnyxu      serverc.lab.example.com  running (31s)  26s ago    31s  -              3.5               2142b60d7974  d9d369e7bb14
```

列出iSCSI网关

```bash
[root@serverc ~]# ceph dashboard iscsi-gateway-list
{"gateways": {"serverc.lab.example.com": {"service_url": "http://admin:admin@172.25.250.12:5000"}}}
```

## 配置iSCSI后端

<mark>这个步骤，用WebUi其实更方便</mark>

从上面的步骤中，可以看到iSCSI容器的id，用podman exec进入配置

```bash
[root@serverc ~]# podman exec -it d9d369e7bb14 gwcli
Warning: Could not load preferences file /root/.gwcli/prefs.bin.
/> ls /
o- / ......................................................................................................................... [...]
  o- cluster ......................................................................................................... [Clusters: 1]
  | o- ceph ............................................................................................................ [HEALTH_OK]
  |   o- pools .......................................................................................................... [Pools: 7]
  |   | o- .rgw.root ............................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 48K]
  |   | o- default.rgw.control ................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- default.rgw.log ........................................................ [(x3), Commit: 0.00Y/29796506K (0%), Used: 408K]
  |   | o- default.rgw.meta ...................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- device_health_metrics ................................................. [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- iscsipool ............................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 24K]
  |   | o- rbdtest ................................................................. [(x3), Commit: 0.00Y/29796506K (0%), Used: 72K]
  |   o- topology ................................................................................................ [OSDs: 9,MONs: 4]
  o- disks ....................................................................................................... [0.00Y, Disks: 0]
  o- iscsi-targets ............................................................................... [DiscoveryAuth: None, Targets: 0]
/>
```

### 创建iSCSI target

进到iSCSI子系统的/iscsi-targets，并完成target创建

```text
/iscsi-targets> create iqn.2024-08.com.example.lab:test
ok
```

看看创建完是什么样子

```text
/iscsi-targets> ls /
o- / ......................................................................................................................... [...]
  o- cluster ......................................................................................................... [Clusters: 1]
  | o- ceph ............................................................................................................ [HEALTH_OK]
  |   o- pools .......................................................................................................... [Pools: 7]
  |   | o- .rgw.root ............................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 48K]
  |   | o- default.rgw.control ................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- default.rgw.log ........................................................ [(x3), Commit: 0.00Y/29796506K (0%), Used: 408K]
  |   | o- default.rgw.meta ...................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- device_health_metrics ................................................. [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- iscsipool ............................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 24K]
  |   | o- rbdtest ................................................................. [(x3), Commit: 0.00Y/29796506K (0%), Used: 72K]
  |   o- topology ................................................................................................ [OSDs: 9,MONs: 4]
  o- disks ....................................................................................................... [0.00Y, Disks: 0]
  o- iscsi-targets ............................................................................... [DiscoveryAuth: None, Targets: 1]
    o- iqn.2024-08.com.example.lab:test .................................................................. [Auth: None, Gateways: 0]
      o- disks .......................................................................................................... [Disks: 0]
      o- gateways ............................................................................................ [Up: 0/0, Portals: 0]
      o- host-groups .................................................................................................. [Groups : 0]
      o- hosts ....................................................................................... [Auth: ACL_ENABLED, Hosts: 0]
```

### 创建iSCSI gateway

创建一个用于客户端的target，记得要先创建本地的主机，主机名和IP地址要核对好，这个是客户端连接的地址

<mark>这里可以配置多个网关来实现多路径连接，比如多个网卡</mark>

```bash
/iscsi-targets> cd /iscsi-targets/iqn.2024-08.com.example.lab:test/gateways

/iscsi-target...test/gateways> create serverc.lab.example.com 172.25.250.12,172.25.249.12
Adding gateway, sync'ing 0 disk(s) and 0 client(s)
ok
/iscsi-target...test/gateways> ls /
o- / ......................................................................................................................... [...]
  o- cluster ......................................................................................................... [Clusters: 1]
  | o- ceph .......................................................................................................... [HEALTH_WARN]
  |   o- pools .......................................................................................................... [Pools: 7]
  |   | o- .rgw.root ............................................................... [(x3), Commit: 0.00Y/29656514K (0%), Used: 48K]
  |   | o- default.rgw.control ................................................... [(x3), Commit: 0.00Y/29656514K (0%), Used: 0.00Y]
  |   | o- default.rgw.log ........................................................ [(x3), Commit: 0.00Y/29656514K (0%), Used: 408K]
  |   | o- default.rgw.meta ...................................................... [(x3), Commit: 0.00Y/29656514K (0%), Used: 0.00Y]
  |   | o- device_health_metrics ................................................. [(x3), Commit: 0.00Y/29656514K (0%), Used: 0.00Y]
  |   | o- iscsipool .......................................................... [(x3), Commit: 100G/29656514K (353%), Used: 314304K]
  |   | o- rbdtest ................................................................. [(x3), Commit: 0.00Y/29656514K (0%), Used: 72K]
  |   o- topology ................................................................................................ [OSDs: 9,MONs: 4]
  o- disks ........................................................................................................ [100G, Disks: 1]
  | o- iscsipool ................................................................................................ [iscsipool (100G)]
  |   o- lxhtestiscsi ...................................................................... [iscsipool/lxhtestiscsi (Online, 100G)]
  o- iscsi-targets ............................................................................... [DiscoveryAuth: None, Targets: 1]
    o- iqn.2024-08.com.example.lab:test .................................................................. [Auth: None, Gateways: 1]
      o- disks .......................................................................................................... [Disks: 0]
      o- gateways ............................................................................................ [Up: 1/1, Portals: 1]
      | o- serverc.lab.example.com .............................................................. [172.25.250.12,172.25.249.12 (UP)]
      o- host-groups .................................................................................................. [Groups : 0]
      o- hosts ....................................................................................... [Auth: ACL_ENABLED, Hosts: 0]
```

### 授权客户端

添加好客户端的initiatorname

```bash
/iscsi-target...test/gateways> cd /iscsi-targets/iqn.2024-08.com.example.lab:test/hosts
/iscsi-target...ab:test/hosts> create iqn.1994-05.com.redhat:cae4921ac1f
ok


/iscsi-target...t:cae4921ac1f> ls /
o- / ......................................................................................................................... [...]
  o- cluster ......................................................................................................... [Clusters: 1]
  | o- ceph ............................................................................................................ [HEALTH_OK]
  |   o- pools .......................................................................................................... [Pools: 7]
  |   | o- .rgw.root ............................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 48K]
  |   | o- default.rgw.control ................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- default.rgw.log ........................................................ [(x3), Commit: 0.00Y/29796506K (0%), Used: 408K]
  |   | o- default.rgw.meta ...................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- device_health_metrics ................................................. [(x3), Commit: 0.00Y/29796506K (0%), Used: 0.00Y]
  |   | o- iscsipool ............................................................... [(x3), Commit: 0.00Y/29796506K (0%), Used: 24K]
  |   | o- rbdtest ................................................................. [(x3), Commit: 0.00Y/29796506K (0%), Used: 72K]
  |   o- topology ................................................................................................ [OSDs: 9,MONs: 4]
  o- disks ....................................................................................................... [0.00Y, Disks: 0]
  o- iscsi-targets ............................................................................... [DiscoveryAuth: None, Targets: 1]
    o- iqn.2024-08.com.example.lab:test .................................................................. [Auth: None, Gateways: 1]
      o- disks .......................................................................................................... [Disks: 0]
      o- gateways ............................................................................................ [Up: 1/1, Portals: 1]
      | o- serverc.lab.example.com ............................................................................ [172.25.250.12 (UP)]
      o- host-groups .................................................................................................. [Groups : 0]
      o- hosts ....................................................................................... [Auth: ACL_ENABLED, Hosts: 1]
        o- iqn.1994-05.com.redhat:cae4921ac1f ........................................................ [Auth: None, Disks: 0(0.00Y)]
```

上面的iqn这部分是客户端的iqn号，要和客户端完全一致，如果cat时文件不存在，就需要安装iscsi客户端

```bnf
[root@clienta ~]# yum install iscsi-initiator-utils -y
[root@clienta ~]# cat /etc/iscsi/initiatorname.iscsi
InitiatorName=iqn.1994-05.com.redhat:cae4921ac1f
```

### 在Ceph中创建并存储lun

进到/disks，在ceph的iSCSI存储池中，创建一个100G且名为lxhtestiscsi的硬盘

```bash
/iscsi-target...ab:test/disks> cd /disks
/disks> create pool=iscsipool image=lxhdisk size=100G
ok

/disks> ls /
o- / ......................................................................................................................... [...]
  o- cluster ......................................................................................................... [Clusters: 1]
  | o- ceph ............................................................................................................ [HEALTH_OK]
  |   o- pools .......................................................................................................... [Pools: 7]
  |   | o- .rgw.root ............................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 48K]
  |   | o- default.rgw.control ................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- default.rgw.log ........................................................ [(x3), Commit: 0.00Y/29778650K (0%), Used: 408K]
  |   | o- default.rgw.meta ...................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- device_health_metrics ................................................. [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- iscsipool .............................................................. [(x3), Commit: 100G/29778650K (352%), Used: 24K]
  |   | o- rbdtest ................................................................. [(x3), Commit: 0.00Y/29778650K (0%), Used: 72K]
  |   o- topology ................................................................................................ [OSDs: 9,MONs: 4]
  o- disks ........................................................................................................ [100G, Disks: 2]
  | o- iscsipool ................................................................................................ [iscsipool (100G)]
  |   o- lxhdisk ............................................................................... [iscsipool/lxhdisk (Unknown, 100G)]
  o- iscsi-targets ............................................................................... [DiscoveryAuth: None, Targets: 1]
    o- iqn.2024-08.com.example.lab:test .................................................................. [Auth: None, Gateways: 1]
      o- disks .......................................................................................................... [Disks: 0]
      o- gateways ............................................................................................ [Up: 1/1, Portals: 1]
      | o- serverc.lab.example.com .............................................................. [172.25.250.12,172.25.249.12 (UP)]
      o- host-groups .................................................................................................. [Groups : 0]
      o- hosts ....................................................................................... [Auth: ACL_ENABLED, Hosts: 1]
        o- iqn.1994-05.com.redhat:cae4921ac1f ........................................................ [Auth: None, Disks: 0(0.00Y)]
```

### 添加存储Lun到iSCSI

将磁盘添加到客户端可用的列表中

```bash
/disks> cd /iscsi-targets/iqn.2024-08.com.example.lab:test/hosts/iqn.1994-05.com.redhat:cae4921ac1f
/iscsi-target...t:cae4921ac1f> disk add iscsipool/lxhdisk
ok

/iscsi-target...t:cae4921ac1f> ls /
o- / ......................................................................................................................... [...]
  o- cluster ......................................................................................................... [Clusters: 1]
  | o- ceph ............................................................................................................ [HEALTH_OK]
  |   o- pools .......................................................................................................... [Pools: 7]
  |   | o- .rgw.root ............................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 48K]
  |   | o- default.rgw.control ................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- default.rgw.log ........................................................ [(x3), Commit: 0.00Y/29778650K (0%), Used: 408K]
  |   | o- default.rgw.meta ...................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- device_health_metrics ................................................. [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- iscsipool .............................................................. [(x3), Commit: 100G/29778650K (352%), Used: 24K]
  |   | o- rbdtest ................................................................. [(x3), Commit: 0.00Y/29778650K (0%), Used: 72K]
  |   o- topology ................................................................................................ [OSDs: 9,MONs: 4]
  o- disks ........................................................................................................ [100G, Disks: 2]
  | o- iscsipool ................................................................................................ [iscsipool (100G)]
  |   o- lxhdisk ............................................................................... [iscsipool/lxhdisk (Unknown, 100G)]
  o- iscsi-targets ............................................................................... [DiscoveryAuth: None, Targets: 1]
    o- iqn.2024-08.com.example.lab:test .................................................................. [Auth: None, Gateways: 1]
      o- disks .......................................................................................................... [Disks: 1]
      | o- iscsipool/lxhdisk .............................................................. [Owner: serverc.lab.example.com, Lun: 0]
      o- gateways ............................................................................................ [Up: 1/1, Portals: 1]
      | o- serverc.lab.example.com .............................................................. [172.25.250.12,172.25.249.12 (UP)]
      o- host-groups .................................................................................................. [Groups : 0]
      o- hosts ....................................................................................... [Auth: ACL_ENABLED, Hosts: 1]
        o- iqn.1994-05.com.redhat:cae4921ac1f ......................................................... [Auth: None, Disks: 1(100G)]
          o- lun 0 ....................................................... [iscsipool/lxhdisk(100G), Owner: serverc.lab.example.com]
```

### 创建客户端使用的账号密码

添加CHAP用户密码用于安全

```bash
/iscsi-target...t:cae4921ac1f> cd /iscsi-targets/iqn.2024-08.com.example.lab:test/hosts/iqn.1994-05.com.redhat:cae4921ac1f
/iscsi-target...t:cae4921ac1f> auth username=lixiaohui password=lixiaohuitest
ok

/iscsi-target...t:cae4921ac1f> ls /
o- / ......................................................................................................................... [...]
  o- cluster ......................................................................................................... [Clusters: 1]
  | o- ceph ............................................................................................................ [HEALTH_OK]
  |   o- pools .......................................................................................................... [Pools: 7]
  |   | o- .rgw.root ............................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 48K]
  |   | o- default.rgw.control ................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- default.rgw.log ........................................................ [(x3), Commit: 0.00Y/29778650K (0%), Used: 408K]
  |   | o- default.rgw.meta ...................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- device_health_metrics ................................................. [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- iscsipool .............................................................. [(x3), Commit: 100G/29778650K (352%), Used: 24K]
  |   | o- rbdtest ................................................................. [(x3), Commit: 0.00Y/29778650K (0%), Used: 72K]
  |   o- topology ................................................................................................ [OSDs: 9,MONs: 4]
  o- disks ........................................................................................................ [100G, Disks: 2]
  | o- iscsipool ................................................................................................ [iscsipool (100G)]
  |   o- lxhdisk ................................................................................ [iscsipool/lxhdisk (Online, 100G)]
  |   o- lxhtestiscsi .................................................................................................. [NOT FOUND]
  o- iscsi-targets ............................................................................... [DiscoveryAuth: None, Targets: 1]
    o- iqn.2024-08.com.example.lab:test .................................................................. [Auth: None, Gateways: 1]
      o- disks .......................................................................................................... [Disks: 1]
      | o- iscsipool/lxhdisk .............................................................. [Owner: serverc.lab.example.com, Lun: 0]
      o- gateways ............................................................................................ [Up: 1/1, Portals: 1]
      | o- serverc.lab.example.com .............................................................. [172.25.250.12,172.25.249.12 (UP)]
      o- host-groups .................................................................................................. [Groups : 0]
      o- hosts ....................................................................................... [Auth: ACL_ENABLED, Hosts: 1]
        o- iqn.1994-05.com.redhat:cae4921ac1f ......................................................... [Auth: CHAP, Disks: 1(100G)]
          o- lun 0 ....................................................... [iscsipool/lxhdisk(100G), Owner: serverc.lab.example.com]
```

### 预览iSCSI后端配置

```bash
/iscsi-target...t:cae4921ac1f> cd /
/> ls /
o- / ......................................................................................................................... [...]
  o- cluster ......................................................................................................... [Clusters: 1]
  | o- ceph ............................................................................................................ [HEALTH_OK]
  |   o- pools .......................................................................................................... [Pools: 7]
  |   | o- .rgw.root ............................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 48K]
  |   | o- default.rgw.control ................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- default.rgw.log ........................................................ [(x3), Commit: 0.00Y/29778650K (0%), Used: 408K]
  |   | o- default.rgw.meta ...................................................... [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- device_health_metrics ................................................. [(x3), Commit: 0.00Y/29778650K (0%), Used: 0.00Y]
  |   | o- iscsipool .............................................................. [(x3), Commit: 100G/29778650K (352%), Used: 24K]
  |   | o- rbdtest ................................................................. [(x3), Commit: 0.00Y/29778650K (0%), Used: 72K]
  |   o- topology ................................................................................................ [OSDs: 9,MONs: 4]
  o- disks ........................................................................................................ [100G, Disks: 2]
  | o- iscsipool ................................................................................................ [iscsipool (100G)]
  |   o- lxhdisk ................................................................................ [iscsipool/lxhdisk (Online, 100G)]
  o- iscsi-targets ............................................................................... [DiscoveryAuth: None, Targets: 1]
    o- iqn.2024-08.com.example.lab:test .................................................................. [Auth: None, Gateways: 1]
      o- disks .......................................................................................................... [Disks: 1]
      | o- iscsipool/lxhdisk .............................................................. [Owner: serverc.lab.example.com, Lun: 0]
      o- gateways ............................................................................................ [Up: 1/1, Portals: 1]
      | o- serverc.lab.example.com .............................................................. [172.25.250.12,172.25.249.12 (UP)]
      o- host-groups .................................................................................................. [Groups : 0]
      o- hosts ....................................................................................... [Auth: ACL_ENABLED, Hosts: 1]
        o- iqn.1994-05.com.redhat:cae4921ac1f ......................................................... [Auth: CHAP, Disks: 1(100G)]
          o- lun 0 ....................................................... [iscsipool/lxhdisk(100G), Owner: serverc.lab.example.com]
```

确认无误后exit退出

```bash
/> exit
[root@serverc ~]#
```

### 开通防火墙

iscsi默认用的3260端口，添加到防火墙例外

```bash
[root@serverc ~]# firewall-cmd --add-port=3260/tcp --add-port=5000/tcp --permanent
success
[root@serverc ~]# firewall-cmd --reload
success
```

### 配置 iSCSI 客户端

#### 安装必备软件包

如果不需要多路径，就不需要额外安装配置`device-mapper-multipath`

```bash
[root@clienta ~]# yum install iscsi-initiator-utils device-mapper-multipath -y
```

#### 配置多路径I/O

启用并创建默认的多路径配置

```bash
[root@clienta ~]# mpathconf --enable --with_multipathd y
```

将以下内容追加到 /etc/multipath.conf 文件

```text
devices {
    device {
        vendor                 "LIO-ORG"
        hardware_handler       "1 alua"
        path_grouping_policy   "failover"
        path_selector          "queue-length 0"
        failback               60
        path_checker           tur
        prio                   alua
        prio_args              exclusive_pref_bit
        fast_io_fail_tmo       25
        no_path_retry          queue
    }
}
```

以下是解释

```text
devices {
    # 开始定义一个设备配置块
    device {
        # 定义设备特定的配置
        vendor                 "LIO-ORG"
        # 指定设备供应商，这里是LIO-ORG，通常是一个正则表达式匹配

        hardware_handler       "1 alua"
        # 指定硬件处理程序，"1 alua"表示使用ALUA（Asymmetric Logical Unit Access）策略，并且优先级为1

        path_grouping_policy   "failover"
        # 定义路径分组策略，"failover"表示当一条路径失败时，流量将切换到其他路径

        path_selector          "queue-length 0"
        # 定义选择活动路径的算法，"queue-length 0"表示选择队列长度为0的路径，即没有等待I/O的路径

        failback               60
        # 定义故障恢复时间，单位为秒。这里设置为60秒，表示在故障路径恢复后，将等待60秒再切换回该路径

        path_checker           tur
        # 定义路径检查器，"tur"表示使用Turbo模式，这是一种快速路径验证方法

        prio                   alua
        # 定义路径选择优先级，"alua"表示根据ALUA优先级选择路径

        prio_args              exclusive_pref_bit
        # 定义优先级参数，"exclusive_pref_bit"表示优先选择设置了独占偏好位的路径

        fast_io_fail_tmo       25
        # 定义快速I/O失败的超时时间，单位为秒。这里设置为25秒

        no_path_retry          queue
        # 当没有可用路径时的重试策略，"queue"表示将I/O请求排队等待
    }
} # 结束设备配置块
```

重新启动 `multipathd` 服务

```bash
[root@clienta ~]# systemctl restart multipathd
```

#### 配置iscsi认证

在文件中找到这几个参数改一下，启用CHAP认证，并设置账号密码，或者直接在文件后加入也行

```bash
[root@cephbackup ~]# vim /etc/iscsi/iscsid.conf
node.session.auth.authmethod = CHAP
node.session.auth.username = lixiaohui
node.session.auth.password = lixiaohui0608
```

重启iSCSI相关服务

```bash
systemctl restart iscsi iscsid
```

#### 执行iscsi发现

<mark>这里成功发现了多路径</mark>

```bash
[root@clienta ~]# iscsiadm -m discovery -t st -p 172.25.250.12
172.25.250.12:3260,1 iqn.2024-08.com.example.lab:test
172.25.249.12:3260,1 iqn.2024-08.com.example.lab:test
```

#### 登陆iscsi

```bash
[root@clienta ~]# iscsiadm -m node -T iqn.2024-08.com.example.lab:test -l
Logging in to [iface: default, target: iqn.2024-08.com.example.lab:test, portal: 172.25.250.12,3260]
iscsiadm: Could not login to [iface: default, target: iqn.2024-08.com.example.lab:test, portal: 172.25.250.12,3260].
iscsiadm: initiator reported error (24 - iSCSI login failed due to authorization failure)
iscsiadm: Could not log into all portals
```

如果这一步登录失败，大概率是没有正确识别到用户名和密码，我们可以用下面的方法更新

```bash
iscsiadm -m node -T iqn.2024-08.com.example.lab:test \
--op update -n node.session.auth.authmethod -v CHAP
iscsiadm -m node -T iqn.2024-08.com.example.lab:test \
--op update -n node.session.auth.username -v lixiaohui
iscsiadm -m node -T iqn.2024-08.com.example.lab:test \
--op update -n node.session.auth.password -v lixiaohuitest
```

确认密码成功添加

```bash
[root@clienta ~]# iscsiadm -m node -T iqn.2024-08.com.example.lab:test --op
delete  new     show    update
[root@clienta ~]# iscsiadm -m node -T iqn.2024-08.com.example.lab:test --op show | grep 'node.session.auth'
node.session.auth.authmethod = CHAP
node.session.auth.username = lixiaohui
node.session.auth.password = ********
node.session.auth.username_in = <empty>
node.session.auth.password_in = <empty>
node.session.auth.chap_algs = MD5
```

再次登录

<mark>成功通过多个路径登录，在一条路断了的时候，可以用另一个路连接</mark>

```bash
[root@clienta ~]# iscsiadm -m node -T iqn.2024-08.com.example.lab:test -l
Logging in to [iface: default, target: iqn.2024-08.com.example.lab:test, portal: 172.25.250.12,3260]
Logging in to [iface: default, target: iqn.2024-08.com.example.lab:test, portal: 172.25.249.12,3260]
Login to [iface: default, target: iqn.2024-08.com.example.lab:test, portal: 172.25.250.12,3260] successful.
Login to [iface: default, target: iqn.2024-08.com.example.lab:test, portal: 172.25.249.12,3260] successful.
```

#### 查询设备列表

发现在系统中添加了两个设备，这是因为我们用多路径管理的

```bash
[root@clienta ~]# lsblk
NAME     MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
sdb        8:16   0  100G  0 disk
└─mpatha 253:0    0  100G  0 mpath
sdc        8:32   0  100G  0 disk
└─mpatha 253:0    0  100G  0 mpath
```

#### 对多路径设备进行分区

这里不要对单个硬盘进行分区，这个没用，需要要对多路径设备分区

```bash
[root@clienta ~]# fdisk /dev/mapper/mpatha

Welcome to fdisk (util-linux 2.32.1).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.


Command (m for help): n
Partition type
   p   primary (0 primary, 0 extended, 4 free)
   e   extended (container for logical partitions)
Select (default p):

Using default response p.
Partition number (1-4, default 1):
First sector (2048-209715199, default 2048):
Last sector, +sectors or +size{K,M,G,T,P} (2048-209715199, default 209715199):

Created a new partition 1 of type 'Linux' and of size 100 GiB.

Command (m for help): w
The partition table has been altered.
Failed to add partition 1 to system: Invalid argument

The kernel still uses the old partitions. The new table will be used at the next reboot.
Syncing disks.
```

检查分区是否就绪

```bash
[root@clienta ~]# lsblk
NAME        MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
sdb           8:16   0  100G  0 disk
└─mpatha    253:0    0  100G  0 mpath
  └─mpatha1 253:1    0  100G  0 part
sdc           8:32   0  100G  0 disk
└─mpatha    253:0    0  100G  0 mpath
  └─mpatha1 253:1    0  100G  0 part
```

#### 格式化挂载使用

```bash
[root@clienta ~]# mkfs.xfs /dev/mapper/mpatha1
meta-data=/dev/mapper/mpatha1    isize=512    agcount=4, agsize=6553536 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=1, rmapbt=0
         =                       reflink=1
data     =                       bsize=4096   blocks=26214144, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
log      =internal log           bsize=4096   blocks=12799, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
Discarding blocks...Done.
```

挂载使用

```bash
[root@clienta ~]# mount /dev/mapper/mpatha1 /mnt
[root@clienta ~]# dd if=/dev/zero of=/mnt/out.file bs=1M count=100
100+0 records in
100+0 records out
104857600 bytes (105 MB, 100 MiB) copied, 0.0902139 s, 1.2 GB/s

[root@clienta ~]# ls /mnt
out.file

[root@clienta ~]# df -h | grep mnt
/dev/mapper/mpatha1  100G  846M  100G   1% /mnt
```

如果要永久写到/etc/fstab中实现自动挂载，要在option选项处加上_netdev，不然系统就起不来了

```bash
[root@clienta ~]# tail -n 1 /etc/fstab
/dev/mapper/mpatha1 /mnt xfs defaults,_netdev 0 0
```
