```text
作者：李晓辉

联系方式：

1. 微信：Lxh_Chat

2. 邮箱：939958092@qq.com
```

# 管理和自定义 CRUSH 映射

## CRUSH 和对象放置策略

Ceph 会使用一种名为 CRUSH（可扩展哈希下的受控复制）的放置算法来计算哪些 OSD 应该存放哪些对象。对象分配到 PG 中，CRUSH 决定这些 PG 应使用哪些 OSD 来存储其对象。

### CRUSH的算法

CRUSH 算法支持 Ceph 客户端直接与 OSD 通信，<mark>从而避免任何中央化服务瓶颈</mark>。Ceph 客户端和 OSD 使用 CRUSH 算法来高效地计算对象位置的信息，<mark>而不依赖中央查找表</mark>。Ceph 客户端检索集群映射，并使用 CRUSH 映射来通过算法确定如何存储和检索数据。这<mark>避免了单一故障点和性能瓶颈</mark>，为 Ceph 集群实现大规模可扩展性。

CRUSH 算法能够将数据均匀分布到对象存储中，管理复制，并且响应系统增长和硬件故障。当添加了新的 OSD 或现有的 OSD 或 OSD 主机出现故障时，Ceph 使用 CRUSH 在活跃的 OSD 之间重新均衡集群中的对象。

### CRUSH Bucket类型

CRUSH 层次结构将 OSD 整理到由不同容器组成的树中，这些容器称为“存储桶”(bucket)。通过创建 CRUSH 映射规则，您可以使 Ceph 将对象的副本放在不同服务器上的 OSD 中，也可以使它放在位于不同的机架或不同数据中心中的服务器上

<mark>存储桶类型包括 `root`、`region`、`datacenter`、`room`、`pod`、`pdu`、`row`、`rack`、`chassis` 以及 `host`</mark>

CRUSH 映射默认层次结构示例：

![](https://gitee.com/cnlxh/cl260/raw/master/images/map/map-crush-default-hierarchy.svg)

## 自定义故障和性能域

配置 CRUSH 映射并<mark>创建单独的故障域</mark>可保证在 OSD 和集群节点<mark>出现故障时也不会丢失任何数据</mark>。集群仅以降级状态运行，直至问题得到解决。

默认情况下，CRUSH 算法将复制的对象放置到不同主机上的 OSD 中。您可自定义 CRUSH 映射，以便将对象副本跨 OSD 放置在<mark>不同的机柜</mark>上，或者放置在<mark>不同机房</mark>的主机上，或者放置在具有<mark>不同PDU</mark>的不同机架上。

另一用例是将带有 SSD 驱动器的 OSD 分配给需要极快存储的应用使用的池，并将带有传统 HDD 的 OSD 分配给支持较低需求工作负载的池。

集群安装流程部署默认的 CRUSH 映射。您可以使用 `ceph osd crush tree/dump` 命令以 JSON 格式打印 CRUSH 映射。也可以导出映射的二进制副本，并将它解译为文本文件：

### 命令查询crush map

```bash
[root@serverc ~]# ceph osd crush tree
ID  CLASS  WEIGHT   TYPE NAME
-1         0.16653  root default
-9         0.04898      host clienta
11    hdd  0.00980          osd.11
12    hdd  0.00980          osd.12
-3         0.02939      host serverc
 1    hdd  0.00980          osd.1
 2    hdd  0.00980          osd.2
10    hdd  0.00980          osd.10
```

### 二进制导出crush map

您可以通过以下命令，解解并手动编辑 CRUSH 映射：

| 命令                                       | 操作                            |
| ---------------------------------------- | ----------------------------- |
| ``ceph osd getcrushmap -o binfile``      | 导出当前映射的二进制副本。                 |
| ``crushtool -d binfile -o textfilepath`` | 将 CRUSH 映射二进制文件解译为文本文件        |
| ``crushtool -c textfilepath -o binfile`` | 从文本编译 CRUSH 映射。               |
| ``crushtool -i binfile --test``          | 对二进制 CRUSH 映射执行空运行，并且模拟创建放置组。 |
| ``ceph osd setcrushmap -i binfile``      | 将二进制 CRUSH 映射导入到集群。           |

**注意**

如果不想进到容器中，需要安装ceph-base软件包

```bash
[root@serverc ~]# cephadm shell
[ceph: root@serverc /]#
[ceph: root@serverc /]# ceph osd getcrushmap -o ./map.bin
48
[ceph: root@serverc /]# crushtool -d ./map.bin -o ./map.txt
[ceph: root@serverc /]# cat map.txt
# begin crush map
tunable choose_local_tries 0
tunable choose_local_fallback_tries 0
tunable choose_total_tries 50
tunable chooseleaf_descend_once 1
tunable chooseleaf_vary_r 1
tunable chooseleaf_stable 1
tunable straw_calc_version 1
tunable allowed_bucket_algs 54

# devices
device 1 osd.1 class hdd
device 2 osd.2 class hdd
device 3 osd.3 class hdd
device 4 osd.4 class hdd
device 5 osd.5 class hdd
device 6 osd.6 class hdd
device 7 osd.7 class hdd
device 8 osd.8 class hdd
device 9 osd.9 class hdd
device 10 osd.10 class hdd
device 11 osd.11 class hdd
device 12 osd.12 class hdd
device 13 osd.13 class hdd
device 15 osd.15 class hdd
device 16 osd.16 class hdd
device 17 osd.17 class hdd
device 18 osd.18 class hdd

# types
type 0 osd
type 1 host
type 2 chassis
type 3 rack
type 4 row
type 5 pdu
type 6 pod
type 7 room
type 8 datacenter
type 9 zone
type 10 region
type 11 root

# buckets
host serverc {
        id -3           # do not change unnecessarily
        id -4 class hdd         # do not change unnecessarily
        # weight 0.029
        alg straw2
        hash 0  # rjenkins1
        item osd.1 weight 0.010
        item osd.2 weight 0.010
        item osd.10 weight 0.010
}
```

### 自定义OSD CRUSH设置

CRUSH 映射包含集群中所有存储设备的列表。每一存储设备都提供有以下信息：

- 存储设备的 ID。

- 存储设备的名称。

- 存储设备的类别。一个存储集群中可以使用多种类型的存储设备，如 HDD、SSD 或 NVMe SSD。

- 存储设备的权重，通常基于以 TB 为单位的容量。例如，4 TB 存储设备的权重约为 4.0。这是设备可以存储的相对数据量，CRUSH 算法用它来帮助确保对象均匀分布。

#### 重新crush map调整权重

可以用`ceph osd crush tree` 来查询他们具体的权重

```bash
[ceph: root@serverc /]# ceph osd crush reweight-all
reweighted crush hierarchy
[ceph: root@serverc /]# ceph osd crush tree
```

#### 管理设备的Class类别

先查看现有的

```bash
[root@serverc ~]# ceph osd crush class ls
[
    "hdd"
]
```

创建一个名为ssd的类别

```bash
[root@serverc ~]# ceph osd crush class create ssd
created class ssd with id 1 to crush map
[root@serverc ~]# ceph osd crush class ls
[
    "hdd",
    "ssd"
]
```

**更改osd的class**

如果osd已经关联了一个class，需要先删除，然后才能关联

```bash
[root@serverc ~]# ceph osd crush set-device-class ssd osd.1
Error EBUSY: osd.1 has already bound to class 'hdd', can not reset class to 'ssd'; use 'ceph osd crush rm-device-class <id>' to remove old class first

[root@serverc ~]# ceph osd crush rm-device-class osd.1
done removing class of osd(s): 1

[root@serverc ~]# ceph osd crush set-device-class ssd osd.1
set osd(s) 1 to class 'ssd'

[root@serverc ~]# ceph osd crush tree | grep osd.1
 1    ssd  0.00980          osd.1
```

## 解读CRUSH规则

CRUSH 映射也包含数据放置规则，它们决定了 PG 如何映射到 OSD 来存储对象副本或纠删代码区块。

`ceph osd crush rule ls` 命令可列出现有的规则，而 ``ceph osd crush rule dump rule_name`` 命令则可打印规则的详细信息。

解译后的 CRUSH 映射也包含规则，它们可能更容易阅读：

```bash
[root@serverc ~]# cephadm shell
[ceph: root@serverc /]#
[ceph: root@serverc /]# ceph osd getcrushmap -o ./map.bin
52
[ceph: root@serverc /]# crushtool -d ./map.bin -o ./map.txt
[ceph: root@serverc /]# cat map.txt
rule replicated_rule { # 规则的名称。使用ceph osd pool create命令创建池时，使用此名称来选择规则
        id 0 # 规则的 ID
        type replicated
        min_size 1 # 如果池形成的副本数少于这个数目，则 CRUSH 不会选择这一规则
        max_size 10 # 如果池形成的副本数多于这个数目，则 CRUSH 不会选择这一规则
        step take default # 取存储桶名称，然后开始沿着树结构往下迭代
        step chooseleaf firstn 0 type host # 选择给定类型 (host) 的存储桶集合，并且从该集合中各个存储桶的子树中选择树叶 (OSD)
        step emit # 输出规则的结果
}
```

例如，您可以创建以下规则，以在不同的机架上选择所需数量的 OSD，但仅从 DC1 数据中心选择：

```bash
rule myrackruleinDC1 {
      id 2
      type replicated
      min_size 1
      max_size 10
      step take DC1
      step chooseleaf firstn 0 type rack
      step emit
}
```

### 使用Ceph命令定制CRUSH地图

创建存储桶的命令格式如下

```bash
ceph osd crush add-bucket name type
```

调整层级的命令格式如下

```bash
ceph osd crush move name type=parent
```

### Crush MAP案例

#### 制定符合业务的crush map

下面的示例描绘了一个现有云计算平台的基本结构

<mark>这里有一家云计算公司名为lxhcloud，在上海这个城市开展业务，在上海的徐汇区有一个机房，在机房中，有两个机柜，两个机柜中，分别有一些服务器，每个服务器分别有一些硬盘</mark>

我们现在来设计一下Ceph的Crush map以便于能实现业务版图

```textile
lxhcloud
└── Shanghai
    ├── Datacenter-XuHui
    │   ├── Rack-1
    │   │   ├── Serverc
    │   │   │   ├── osd.1
    │   │   │   ├── osd.2
    │   │   │   └── osd.3
    │   │   ├── Serverd
    │   │   │   ├── osd.3
    │   │   │   ├── osd.5
    │   │   │   └── osd.7
    │   ├── Rack-2
    │   │   ├── Servere
    │   │   │   ├── osd.4
    │   │   │   ├── osd.6
    │   │   │   └── osd.8
```

先查询Ceph中现有的crush map

```bash
[root@serverc ~]# ceph osd crush tree
ID   CLASS  WEIGHT   TYPE NAME
 -1         0.08817  root default
 -3         0.02939      host serverc
  0    hdd  0.00980          osd.0
  1    hdd  0.00980          osd.1
  2    hdd  0.00980          osd.2
 -5         0.02939      host serverd
  3    hdd  0.00980          osd.3
  5    hdd  0.00980          osd.5
  7    hdd  0.00980          osd.7
 -7         0.02939      host servere
  4    hdd  0.00980          osd.4
  6    hdd  0.00980          osd.6
  8    hdd  0.00980          osd.8
```

先创建出这家公司

```bash
[root@serverc ~]# ceph osd crush add-bucket lxhcloud root
added bucket lxhcloud type root to crush map
```

创建出上海这个城市

```bash
[root@serverc ~]# ceph osd crush add-bucket Shanghai region
added bucket Shanghai type region to crush map
```

再创建出上海的徐汇机房

```bash
[root@serverc ~]# ceph osd crush add-bucket Datacenter-XuHui datacenter
added bucket Datacenter-XuHui type datacenter to crush map
```

再创建出两个机柜

```bash
[root@serverc ~]# ceph osd crush add-bucket Rack-1 rack
added bucket Rack-1 type rack to crush map
[root@serverc ~]# ceph osd crush add-bucket Rack-2 rack
added bucket Rack-2 type rack to crush map
```

把这几个对象按照业务整合起来，形成层级关系

```bash
[root@serverc ~]# ceph osd crush move Shanghai root=lxhcloud
moved item id -10 name 'Shanghai' to location {root=lxhcloud} in crush map
[root@serverc ~]# ceph osd crush move Datacenter-XuHui region=Shanghai
moved item id -11 name 'Datacenter-XuHui' to location {region=Shanghai} in crush map
[root@serverc ~]# ceph osd crush move Rack-1 datacenter=Datacenter-XuHui
moved item id -15 name 'Rack-1' to location {datacenter=Datacenter-XuHui} in crush map
[root@serverc ~]# ceph osd crush move Rack-2 datacenter=Datacenter-XuHui
moved item id -16 name 'Rack-2' to location {datacenter=Datacenter-XuHui} in crush map
```

再次查询crush map，发现层级关系是有了，但是主机还是在default这个根下

```bash
[root@serverc ~]# ceph osd crush tree
ID   CLASS  WEIGHT   TYPE NAME
 -9               0  root lxhcloud
-10               0      region Shanghai
-11               0          datacenter Datacenter-XuHui
-15               0              rack Rack-1
-16               0              rack Rack-2
 -1         0.08817  root default
 -3         0.02939      host serverc
  0    hdd  0.00980          osd.0
  1    hdd  0.00980          osd.1
  2    hdd  0.00980          osd.2
 -5         0.02939      host serverd
  3    hdd  0.00980          osd.3
  5    hdd  0.00980          osd.5
  7    hdd  0.00980          osd.7
 -7         0.02939      host servere
  4    hdd  0.00980          osd.4
  6    hdd  0.00980          osd.6
  8    hdd  0.00980          osd.8
```

移动服务器过来

```bash
[root@serverc ~]# ceph osd crush move serverc rack=Rack-1
moved item id -3 name 'serverc' to location {rack=Rack-1} in crush map
[root@serverc ~]# ceph osd crush move serverd rack=Rack-1
moved item id -5 name 'serverd' to location {rack=Rack-1} in crush map
[root@serverc ~]# ceph osd crush move servere rack=Rack-2
moved item id -7 name 'servere' to location {rack=Rack-2} in crush map
```

再次查询crush map，发现我们已经按照业务规划，做了crush map制定

```bash
[root@serverc ~]# ceph osd crush tree
ID   CLASS  WEIGHT   TYPE NAME
 -9         0.08817  root lxhcloud
-10         0.08817      region Shanghai
-11         0.08817          datacenter Datacenter-XuHui
-15         0.05878              rack Rack-1
 -3         0.02939                  host serverc
  0    hdd  0.00980                      osd.0
  1    hdd  0.00980                      osd.1
  2    hdd  0.00980                      osd.2
 -5         0.02939                  host serverd
  3    hdd  0.00980                      osd.3
  5    hdd  0.00980                      osd.5
  7    hdd  0.00980                      osd.7
-16         0.02939              rack Rack-2
 -7         0.02939                  host servere
  4    hdd  0.00980                      osd.4
  6    hdd  0.00980                      osd.6
  8    hdd  0.00980                      osd.8
 -1               0  root default
```

#### 修改Crush map的放置规则

只创建crush map是不够的，还得修改现有的规则来默认使用我们的新crush map，而不是使用旧的crush map

<mark>导出当前映射的二进制副本</mark>

```bash
[root@serverc ~]# cephadm shell
[ceph: root@serverc /]# ceph osd getcrushmap -o lxh.bin
32
```

将 CRUSH 映射二进制文件解译为文本文件

```bash
[ceph: root@serverc /]# crushtool -d lxh.bin -o lxh.txt
```

修改lxh.txt为以下内容，这个文件很长，这里只修改# rules部分，在最下面

```bash
[ceph: root@serverc /]# vi lxh.txt
```

这里将step take 后面的default改为了lxhcloud，将step chooseleaf firstn 0 type后面的host改为了osd

```text
# rules
rule replicated_rule {
        id 0
        type replicated
        min_size 1
        max_size 10
        step take lxhcloud
        step chooseleaf firstn 0 type osd
        step emit
}
```

从文本重新编译 CRUSH 映射

```bash
[ceph: root@serverc /]# crushtool -c lxh.txt -o new.bin
```

对二进制 CRUSH 映射执行空运行，并且模拟创建放置组

```bash
[ceph: root@serverc /]# crushtool -i new.bin --test --show-mappings | more
CRUSH rule 0 x 0 [6]
CRUSH rule 0 x 1 [5]
CRUSH rule 0 x 2 [8]
CRUSH rule 0 x 3 [4]
CRUSH rule 0 x 4 [5]
```

模拟看上去没问题，就把我们的新映射，导入到集群

<mark>需要注意，这里导入成功之后，原有的数据会重新做位置移动，会有大量的I/O和网络流量，集群会暂时处于警告状态</mark>

```bash
[ceph: root@serverc /]# ceph osd setcrushmap -i new.bin
33
[ceph: root@serverc /]# ceph -s
  cluster:
    id:     2ae6d05a-229a-11ec-925e-52540000fa0c
    health: HEALTH_WARN
            Reduced data availability: 3 pgs inactive, 21 pgs peering
            Degraded data redundancy: 172/663 objects degraded (25.943%), 25 pgs degraded

  services:
    mon: 4 daemons, quorum serverc.lab.example.com,clienta,serverd,servere (age 6m)
    mgr: serverc.lab.example.com.aiqepd(active, since 26h), standbys: clienta.nncugs, servere.kjwyko, serverd.klrkci
    osd: 9 osds: 9 up (since 26h), 9 in (since 2y); 28 remapped pgs
    rgw: 2 daemons active (2 hosts, 1 zones)

  data:
    pools:   5 pools, 105 pgs
    objects: 221 objects, 4.9 KiB
    usage:   507 MiB used, 89 GiB / 90 GiB avail
    pgs:     48.571% pgs not active
             172/663 objects degraded (25.943%)
             76/663 objects misplaced (11.463%)
             41 active+clean
             23 remapped+peering
             14 activating+undersized+degraded+remapped
             8  active+recovery_wait+degraded
             7  activating
             4  activating+undersized+remapped
             3  active+recovery_wait+undersized+degraded+remapped
             3  activating+remapped
             1  active+recovering+undersized+remapped
             1  active

  io:
    recovery: 0 B/s, 0 objects/s
```

#### 创建新的Crush map放置规则

如果暂时不想修改默认规则，或者对于导出和编译过程不是很熟悉，可以创建新的规则，然后将池的生效规则进行修改即可

创建的命令格式为：

```textile
ceph osd crush rule create-replicated/create-erasure <name> <root> <type> [<class>]
```

创建一个将数据放到lxhcloud的不同osd的复制池规则

**复制池**

```bash
[root@serverc ~]# ceph osd crush rule create-replicated lxhrep lxhcloud osd
[root@serverc ~]# ceph osd crush rule ls
replicated_rule
lxhrep
```

**纠删代码池**

```bash
[root@serverc ~]# ceph osd erasure-code-profile set lxhecprofile k=4 m=2 crush-root=lxhcloud crush-failure-domain=osd
[root@serverc ~]# ceph osd erasure-code-profile get lxhecprofile
crush-device-class=
crush-failure-domain=osd
crush-root=lxhcloud
jerasure-per-chunk-alignment=false
k=4
m=2
plugin=jerasure
technique=reed_sol_van
w=8
```

Ceph 会自动为您创建的每个纠删代码池创建规则。规则的名称是新池的名称

```bash
[root@serverc ~]# ceph osd pool create ecpool erasure lxhecprofile
pool 'ecpool' created
[root@serverc ~]# ceph osd crush rule ls
replicated_rule
lxhrep
ecpool
```

#### 修改现有存储池的crush规则

将现有池的crush规则修改到lxhrep这个规则

以下命令批量修改了现有池的放置规则为lxhrep

```bash
[root@serverc ~]# for pool in $(ceph osd pool ls);do ceph osd pool set $pool crush_rule lxhrep;done
set pool 1 crush_rule to lxhrep
set pool 2 crush_rule to lxhrep
set pool 3 crush_rule to lxhrep
set pool 4 crush_rule to lxhrep
set pool 5 crush_rule to lxhrep
```

## 优化放置组

放置组自动扩展程序可用于优化 PG 分布，并默认开启。必要时，您还可手动设置每个池的 PG 数量，红帽建议按照每个 OSD 大约 100 到 200 个 PG 的数量设置

### 计算放置组的数量

对于单个池的集群，可以使用以下公式，每个OSD 100个放置组

```bash
Total PGs = (OSDs * 100)/Number of replicas 
```

Red Hat推荐使用每个池计算Ceph放置组，https://access.redhat.com/labs/cephpgc/manual/

### 手动映射PG

使用 `ceph osd pg-upmap-items` 命令将 PG 手动映射到特定的 OSD，**`luminous`** 版本及以上的Ceph版本才支持，先设置一下集群需要的最小客户端为luminous

```bash
[root@serverc ~]# ceph osd set-require-min-compat-client luminous
set require_min_compat_client to luminous
```

下面的例子将PG 7.16从ODs 2和 [3,0,4,2,7,5]映射到[1 2 3 4 5 6]:

```bash
[root@serverc ~]# ceph pg map 7.16
osdmap e273 pg 7.16 (7.16) -> up [3,0,4,2,7,5] acting [3,0,4,2,7,5]
[root@serverc ~]# ceph osd pg-upmap-items 7.16 1 2 3 4 5 6
set 7.16 pg_upmap_items mapping to [1->2,3->4,5->6]
[root@serverc ~]# ceph pg map 7.16
```

像这样重新映射数百个 PG 是不切实际的。这时可使用 `osdmaptool` 命令，它获取一个池的实际地图，分析它，再生成要运行的 `ceph osd pg-upmap-items` 命令，从而实现理想的分布

1. 将映射导出到一个文件，下面的命令将映射保存到./ om文件:

```bash
[ceph: root@serverc /]# ceph osd getmap -o ./om
got osdmap epoch 278
```

2. 使用 `osdmaptool` 命令的 `--test-map-pgs` 选项，显示实际的 PG 分布。以下命令打印 ID 为 6 的池的分布：

<mark>我们发现，count部分基本是均衡的，不需要再次优化</mark>

```bash
[ceph: root@serverc /]# osdmaptool ./om --test-map-pgs --pool 6
osdmaptool: osdmap file './om'
pool 6 pg_num 32
#osd    count   first   primary c wt    wt
osd.0   13      2       2       0.00999451      1
osd.1   13      4       4       0.00999451      1
osd.2   17      3       3       0.00999451      1
osd.3   13      1       1       0.00999451      1
osd.4   15      5       5       0.00999451      1
osd.5   12      3       3       0.00999451      1
osd.6   12      6       6       0.00999451      1
osd.7   15      2       2       0.00999451      1
osd.8   18      6       6       0.00999451      1
 in 9
 avg 14 stddev 2.0548 (0.146772x) (expected 3.55556 0.253968x))
 min osd.5 12
 max osd.8 18
size 4  32
```

输出显示了osd.2只有27个PG而osd.1有39 PG

3. 生成命令来重新平衡 PG。使用 `osdmaptool` 命令的 `--upmap` 选项，将命令保存到文件中：

`--upmap-deviation` 这个参数默认不需要指定，我只是为了确保有内容输出而已，这个值默认是5，就是这些count的偏差值

```bash
[ceph: root@serverc /]# osdmaptool ./om --upmap ./cmds.txt --pool 6 --upmap-deviation 1
osdmaptool: osdmap file './om'
writing upmap command output to: ./cmds.txt
checking for upmap cleanups
upmap, max-count 10, max deviation 1
pools ecpool abc device_health_metrics default.rgw.meta .rgw.root default.rgw.log default.rgw.control
prepared 10/10 changes
[ceph: root@serverc /]# cat cmds.txt
ceph osd pg-upmap-items 7.6 7 5
ceph osd pg-upmap-items 7.7 3 6
ceph osd pg-upmap-items 7.9 4 5
ceph osd pg-upmap-items 7.16 5 6
ceph osd pg-upmap-items 7.17 2 8 7 6
ceph osd pg-upmap-items 7.18 0 5
ceph osd pg-upmap-items 7.19 3 6
ceph osd pg-upmap-items 7.1a 3 8
ceph osd pg-upmap-items 7.1b 2 6
```

4. 执行命令:

```bash
[ceph: root@serverc /]# bash cmds.txt
set 7.6 pg_upmap_items mapping to [7->5]
set 7.7 pg_upmap_items mapping to [3->6]
set 7.9 pg_upmap_items mapping to [4->5]
set 7.16 pg_upmap_items mapping to [5->6]
set 7.17 pg_upmap_items mapping to [2->8,7->6]
set 7.18 pg_upmap_items mapping to [0->5]
set 7.19 pg_upmap_items mapping to [3->6]
set 7.1a pg_upmap_items mapping to [3->8]
set 7.1b pg_upmap_items mapping to [2->6]
```

# 管理 OSD 映射

## 描述 OSD 映射

OSD 映射包含每个 OSD 的地址和状态、池列表和详情，以及其他信息，如 OSD 接近容量限制信息

当集群的基础架构有变化时，例如 OSD 加入或离开集群， MON 会相应地更新对应的映射。MON 维护映射修订的历史记录。Ceph 使用递增整数的有序集合（称为 *epoch*）来标识各个映射的每一版本

使用 `ceph status -f json-pretty` 命令可显示每个映射的epoch。使用 ``ceph map dump`` 子命令来显示各个映射，如 `ceph osd dump`。每当 OSD 加入或离开集群时，Ceph 都会更新 OSD 映射。OSD 可能会因为 OSD 故障或硬件故障而离开 Ceph 集群。

```bash
[root@serverc ~]# ceph status -f json-pretty | more

{
    "fsid": "2ae6d05a-229a-11ec-925e-52540000fa0c",
    "health": {
        "status": "HEALTH_OK",
        "checks": {},
        "mutes": []
    },
    "election_epoch": 122,
    "quorum": [
        0,
        1,
        2,
        3
    ],
    "quorum_names": [
        "serverc.lab.example.com",
        "clienta",
        "serverd",
        "servere"
    ],
    "quorum_age": 3832,
    "monmap": {
        "epoch": 4,
        "min_mon_release_name": "pacific",
        "num_mons": 4
    },
    "osdmap": {
        "epoch": 290,
        "num_osds": 9,
        "num_up_osds": 9,
        "osd_up_since": 1722915456,
        "num_in_osds": 9,
        "osd_in_since": 1635491258,
        "num_remapped_pgs": 0
    },
```

查看osd的信息

果然看到了epoch和池信息，osd信息等

```bash
[root@serverc ~]# ceph osd dump | more
epoch 290
fsid 2ae6d05a-229a-11ec-925e-52540000fa0c
created 2021-10-01T09:30:32.028240+0000
modified 2024-08-07T06:56:44.969909+0000
flags sortbitwise,recovery_deletes,purged_snapdirs,pglog_hardlimit
crush_version 36
full_ratio 0.95
backfillfull_ratio 0.9
nearfull_ratio 0.85
require_min_compat_client luminous
min_compat_client luminous
require_osd_release pacific
stretch_mode_enabled false
pool 1 'device_health_metrics' replicated size 3 min_size 2 crush_rule 1 object_hash rjenkins pg_num 1 pgp_num 1 autoscale_mode on last_c
hange 261 flags hashpspool stripe_width 0 pg_num_min 1 application mgr_devicehealth
pool 2 '.rgw.root' replicated size 3 min_size 2 crush_rule 1 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 262
flags hashpspool stripe_width 0 application rgw
pool 3 'default.rgw.log' replicated size 3 min_size 2 crush_rule 1 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_chang
e 263 flags hashpspool stripe_width 0 application rgw
pool 4 'default.rgw.control' replicated size 3 min_size 2 crush_rule 1 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_c
hange 264 flags hashpspool stripe_width 0 application rgw
pool 5 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 1 object_hash rjenkins pg_num 8 pgp_num 8 autoscale_mode on last_change
 265 lfor 0/184/182 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 8 application rgw
pool 6 'abc' erasure profile default size 4 min_size 3 crush_rule 3 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_chan
ge 290 flags hashpspool stripe_width 8192 application rbd
pool 7 'ecpool' erasure profile lxhecprofile size 6 min_size 5 crush_rule 3 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on l
ast_change 289 flags hashpspool stripe_width 16384 application rbd
max_osd 9
osd.0 up   in  weight 1 up_from 190 up_thru 281 down_at 189 last_clean_interval [24,185) [v2:172.25.250.12:6800/1196803373,v1:172.25.250.
12:6801/1196803373] [v2:172.25.249.12:6802/1196803373,v1:172.25.249.12:6803/1196803373] exists,up 5be66be9-8262-4c4b-9654-ed549f6280f7
osd.1 up   in  weight 1 up_from 189 up_thru 276 down_at 188 last_clean_interval [24,185) [v2:172.25.250.12:6807/4220845531,v1:172.25.250.
12:6808/4220845531] [v2:172.25.249.12:6809/4220845531,v1:172.25.249.12:6810/4220845531] exists,up 3f751363-a03c-4b76-af92-8114e38bfa09
```

## 分析OSD Map更新

每当有OSD加入或离开集群时，Ceph都会更新OSD的map。一个OSD可以因为OSD故障或硬件故障而离开Ceph集群

<mark>OSD 不使用leader来管理 OSD 映射</mark>；它们会在自身之间传播映射。OSD 会利用 OSD 映射epoch标记它们交换的每一条消息。当 OSD 检测到自己已拖后时，它会使用其对等 OSD 执行映射更新，接收节点会执行<mark>增量映射更新</mark>

## 传播 OSD 映射

OSD 定期向监控器报告自己的状态。此外，OSD 会交换心跳，这样 OSD 可以检测对等点的故障，并将该事件报告给监控器。

当leader监控器了解到 OSD 故障时，它会更新映射，递增epoch，并使用 Paxos 更新协议来通知其他监控器，同时撤销它们的租用。在多数监控器确认更新并且集群具有仲裁后，leader监控器会发布新的租用，使得监控器能够分发更新的 OSD 映射。这种方法可避免映射epoch后退到集群中的任何位置并查找仍然有效的旧租用。
