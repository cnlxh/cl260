```text
作者：李晓辉

联系方式：

1. 微信：Lxh_Chat

2. 邮箱：939958092@qq.com 
```

# 优化红帽Ceph存储性能

## 定义性能调优

Ceph 集群的性能调优具有三个指标：延迟、IOPS（每秒输入/输出操作数）以及吞吐量。

### 调优目标

根据您的工作负载，调优目标应当是：

- 降低延迟

- 提高设备的 IOPS

- 增加块大小

## 优化Ceph性能

下面的部分描述了调优Ceph的推荐实践

### Ceph部署

MON 性能对集群总体性能至关重要。MON 应当位于大型部署的<mark>专用节点上</mark>。为确保正确仲裁，MON 的数量应为<mark>奇数</mark>。

在写入到 BlueStore 块数据库和预写式日志 (WAL) 时，使用 SSD 或 NVMe 来最大限度提高效率。

Ceph RADOS 网关的工作负载通常是吞吐量密集型，Ceph 存储可提供存储桶索引自动重新划分功能

存放目录结构和其他索引的元数据池可能会成为 CephFS 瓶颈。若要最大限度降低这一限制，需将 SSD 设备用于元数据池。

## 放置组算法

*放置组总数 = (OSD* 100)/副本数*。

为每个池应用这个公式，以获取集群的 PG 总数。红帽建议每个 OSD 要有 100 到 200 个 PG。

PG 自动扩展功能支持 Ceph 提出建议并<mark>自动调整 PG 的数量</mark>。此功能默认会在创建池时启用

## 设计集群架构

在设计Ceph集群时，考虑扩展选择，以匹配未来的数据需求，并使用正确的网络大小和体系结构促进足够的吞吐量

### 可扩展性

可用两种方式扩展集群化存储：

- **横向扩展**，即添加更多节点到集群。

- **纵向扩展**，即添加更多资源到现有节点。

纵向扩展要求节点能够接受更多的 CPU 和 RAM 资源，以处理磁盘数量和磁盘大小的增加。横向扩展需要添加具有相似资源和容量的节点，以匹配集群的现有节点，实现平衡操作。

### 网络的最佳实践

- 为增强性能并为故障排除提供更好的隔离，将不同的网络用于 OSD 流量和客户端流量。

- 至少，为存储集群配置 10 GB 或更大的网络。 1 GB 网络不适合生产环境。

- 根据集群和客户端流量以及存储的数据量评估网络大小。

- 强烈建议进行网络监控。

- 尽可能使用独立 NIC 来连接网络，或者使用独立端口。

推荐不同的网络用于 OSD 和客户端流量:

Ceph 守护进程自动绑定到正确的接口，比如将 MON 绑定到公共网络，并将 OSD 绑定到公共和集群网络。

![](https://gitee.com/cnlxh/cl260/raw/master/images/tuning/tuning-tuning-cephperf-network.svg)

### OSD恢复与回填

当 Ceph 在集群中添加或移除 OSD 时，Ceph 会重新平衡 PG，以使用新的 OSD 或重新创建存储在被移除 OSD 中的副本。这些<mark>回填和恢复</mark>操作可能会产生<mark>大量的集群网络流量</mark>，从而影响性能。

Ceph 可提供参数来限制回填和恢复操作的 I/O 或网络活动。

下表包括其中的一些参数：

| 参数                            | 定义                  |
| ----------------------------- | ------------------- |
| `osd_recovery_op_priority`    | 恢复操作的优先级            |
| `osd_recovery_max_active`     | 每个 OSD 并行的最大活跃恢复请求数 |
| `osd_recovery_threads`        | 用于数据恢复的线程数          |
| `osd_max_backfills`           | OSD 回填操作的最大数        |
| `osd_backfill_scan_min`       | 每次回填扫描的最小对象数量       |
| `osd_backfill_scan_max`       | 每次回填扫描的最大对象数量       |
| `osd_backfill_full_ratio`     | 向 OSD 发出的回填请求的阈值    |
| `osd_backfill_retry_interval` | 在重试回填请求前等待的秒数       |

## 配置硬件

红帽为三个性能优先级提出了以下硬件配置：

优化 IOPS

- 每个 NVMe 设备使用两个 OSD。

- NVMe 驱动器将数据、块数据库和 WAL 并置在同一存储设备上。

- 假设 CPU 为 2 GHz，每个 NVMe 使用 10 个内核或每个 SSD 使用 2 个内核。

- 分配 16 GB RAM 作为基线，外加每个 OSD 5GB。

- 每 2 个 OSD 使用 10 GbE NIC。

优化吞吐量

- 每个 HDD 使用一个 OSD。

- 将块数据库和 WAL 放在 SSD 或 NVMe 上。

- 使用至少 7,200 RPM 的 HDD 驱动器。

- 假设 CPU 为 2 GHz，每个 HDD 使用二分之一内核。

- 分配 16 GB RAM 作为基线，外加每个 OSD 5GB。

- 每 12 个 OSD 使用 10 GbE NIC。

优化容量

- 每个 HDD 使用一个 OSD。

- HDD 将数据、块数据库和 WAL 并置在同一存储设备上。

- 使用至少 7,200 RPM 的 HDD 驱动器。

- 假设 CPU 为 2 GHz，每个 HDD 使用二分之一内核。

- 分配 16 GB RAM 作为基线，外加每个 OSD 5GB。

- 每 12 个 OSD 使用 10 GbE NIC。

## 使用Ceph性能工具进行调优

## 性能压力工具

Red Hat Ceph Storage提供了对Ceph集群进行压力测试和基准测试的工具。

### RADOS bench命令

该工具可对集群执行写入和读取测试，并提供统计数据。该命令的一般语法为：

```bash
[admin@node ~]$ rados -p pool-name bench seconds write|seq|rand \
-b objsize -t concurrency
```

以下是该工具的常用参数：

- `seq` 和 `rand` 测试是连续和随机 read 基准测试。这些测试需要先使用 `--no-cleanup` 选项运行 `write` 基准测试。RADOS bench 默认会删除为写入测试创建的对象。`--no-cleanup` 选项可保留对象，非常适合对相同对象上执行多项测试。

- 默认对象大小 `objsize` 为 4 MB。

- 默认的并发操作数 `concurrency` 是 16。
  
  使用 `--no-cleanup` 选项时，您必须手动删除在运行 `rados bench` 命令后池中遗留的数据。

例如，以下信息由 `rados bench` 命令提供，包括吞吐量、IOPS 和延迟：

```bash
[root@serverc ~]# ceph osd pool create testpool
pool 'testpool' created
[root@serverc ~]# rados bench -p testpool 10 write
hints = 1
Maintaining 16 concurrent writes of 4194304 bytes to objects of size 4194304 for up to 10 seconds or 0 objects
Object prefix: benchmark_data_serverc.lab.example.com_70765
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0       0         0         0         0         0           -           0
    1      16        41        25   99.9652       100    0.359402    0.458076
    2      16        83        67   133.957       168    0.541215    0.418786
    3      16       129       113   150.601       184    0.186691    0.386582
    4      16       153       137   136.937        96    0.963831    0.428352
    5      16       178       162   129.542       100     0.25583    0.428845
    6      16       184       168   111.926        24     1.67054    0.472503
    7      16       193       177   101.044        36     2.79377    0.534967
    8      16       211       195   97.4086        72    0.978128    0.628561
    9      16       220       204   90.5859        36    0.388969    0.617214
   10      15       258       243   97.1097       156    0.567263    0.637828
Total time run:         10.1937
Total writes made:      258
Write size:             4194304
Object size:            4194304
Bandwidth (MB/sec):     101.239
Stddev Bandwidth:       57.2573
Max bandwidth (MB/sec): 184
Min bandwidth (MB/sec): 24
Average IOPS:           25
Stddev IOPS:            14.3143
Max IOPS:               46
Min IOPS:               6
Average Latency(s):     0.626779
Stddev Latency(s):      0.59911
Max latency(s):         3.32423
Min latency(s):         0.102171
Cleaning up (deleting benchmark objects)
Removed 258 objects
Clean up completed and total clean up time :0.295582
```

### RBD bench命令

RBD bench 测量您为测试创建的现有镜像的 I/O 吞吐量和延迟。

这些是默认值：

- 如果您不为 size 参数提供后缀，该命令会假定以字节数为单位。

- 默认的池名称是 `rbd`。

- `--io-size` 的默认值是 4096 字节。

- `--io-threads` 的默认值是 16。

- `--io-total` 的默认值是 1 GB。

- `--io-pattern` 的默认值是 seq，表示按顺序。

例如，`rbd bench` 命令可提供一些信息，包括吞吐量和延迟：

```bash
[root@serverc ~]# ceph osd pool create testpool
[root@serverc ~]# rbd create --size 5G testpool/testimage
[root@serverc ~]# rbd bench --io-type write testimage --pool=testpool
bench  type write io_size 4096 io_threads 16 bytes 1073741824 pattern sequential
  SEC       OPS   OPS/SEC   BYTES/SEC
    1     20928   11052.1    43 MiB/s
    2     24496   12249.7    48 MiB/s
    3     59664   19899.7    78 MiB/s
    4     93744   23445.5    92 MiB/s
    5    125344   25076.7    98 MiB/s
    6    153872   32369.7   126 MiB/s
    7    173808     29868   117 MiB/s
    8    211424   30339.5   119 MiB/s
    9    240928   29436.4   115 MiB/s
elapsed: 9   ops: 262144   ops/sec: 27238.2   bytes/sec: 106 MiB/s
```

## 通过清理保持数据一致性

OSD 负责使用轻度清理和深度清理来验证数据一致性。

- 轻度清理可验证对象的存在性、校验和以及大小。默认每天执行一次轻度清理

- 深度清理可读取数据并重新计算和验证对象的校验和。每周执行一次深度清理

### 轻度清理

轻度清理功能具有以下调优参数：`osd_scrub_begin_hour = begin_hour`:: `begin_hour` 参数指定开始清理的时间。有效值为 0 到 23。如果值设置为 0，并且 `osd_scrub_end_hour` 也为 0，则一整天都可以进行清理。

`osd_scrub_end_hour = end_hour`

`end_hour` 参数指定停止清理的时间。有效值为 0 到 23。如果值设置为 0，并且 `osd_scrub_begin_hour` 也为 0，则一整天都可以进行清理。

`osd_scrub_load_threshold`

在系统负载低于 `getloadavg() / number online CPUs` 参数定义的阈值时执行清理。默认值为 0.5。

`osd_scrub_min_interval`

如果负载低于 `osd_scrub_load_threshold` 参数中设置的阈值，则执行清理的频率不应超过此参数定义的秒数。默认值为 1 天。

`osd_scrub_interval_randomize_ratio`

为 `osd_scrub_min_interval` 参数中定义的值添加随机延迟。默认值为 0.5。

`osd_scrub_max_interval`

不论负载如何，执行清理的等待时间不要超过这个期限。默认值为 7 天。

`osd_scrub_priority`

使用此参数可设置清理操作的优先级。默认值为 5。此值与 `osd_client_op_priority` 的值相关，后者的默认优先级更高，为 63。

```bash
[root@serverc ~]# ceph config ls | grep osd_scrub_begin_hour
osd_scrub_begin_hour
[root@serverc ~]# ceph config get osd osd_scrub_begin_hour
0
```

### 深度清理

以下参数对于调优深度清理来说最为关键：

`osd_deep_scrub_interval`

深度清理的间隔。默认值为 7 天。

`osd_scrub_sleep`

在深度清理磁盘读取之间引入一个暂停。增大这个值可以减慢清理操作的速度，并且降低对客户端操作的影响。默认值为 0。

您可通过下列命令，使用外部调度程序来实施轻度和深度清理：

- `ceph pg dump` 命令会在 `LAST_SCRUB` 和 `LAST_DEEP_SCRUB` 列显示最近发生的轻度和深度清理。

- ``ceph pg scrub *`pg-id`*`` 命令可将深度清理调度到特定 PG。

- ``ceph pg deep-scrub *`pg-id`*``命令可将深度清理调度到特定 PG。

使用 ``ceph osd pool set *`pool-name parameter value`*`` 命令可以为特定的池设置这些参数。

**用于清理的池参数**

还可使用下列池参数，在池级别上控制轻度和深度清理：

`noscrub`

如果设置为 `TRUE`，Ceph 不会对池进行轻度清理。默认值为 `FALSE`。

`nodeep-scrub`

如果设置为 `TRUE`，Ceph 不会对池进行深度清理。默认值为 `FALSE`

`scrub_min_interval`

执行清理的时间间隔不少于此参数定义的秒数。如果设置为 0（默认值），则 Ceph 会使用 `osd_scrub_min_interval` 全局配置参数。

`scrub_max_interval`

执行池清理前的等待时间不要超过这个期限。如果设置为 0（默认值），则 Ceph 会使用 `osd_scrub_max_interval` 全局配置参数。

`deep_scrub_interval`

深度清理的间隔。如果设置为 0（默认值），则 Ceph 会使用 `osd_deep_scrub_interval` 全局配置参数。

```bash
[root@serverc ~]# ceph config get osd osd_scrub_min_interval
86400.000000
[root@serverc ~]# ceph config get osd osd_scrub_max_interval
604800.000000
```

### 用于清理的池参数

还可使用下列池参数，在池级别上控制轻度和深度清理：

`noscrub`

如果设置为 `TRUE`，Ceph 不会对池进行轻度清理。默认值为 `FALSE`。

`nodeep-scrub`

如果设置为 `TRUE`，Ceph 不会对池进行深度清理。默认值为 `FALSE`

`scrub_min_interval`

执行清理的时间间隔不少于此参数定义的秒数。如果设置为 0（默认值），则 Ceph 会使用 `osd_scrub_min_interval` 全局配置参数。

`scrub_max_interval`

执行池清理前的等待时间不要超过这个期限。如果设置为 0（默认值），则 Ceph 会使用 `osd_scrub_max_interval` 全局配置参数。

`deep_scrub_interval`

深度清理的间隔。如果设置为 0（默认值），则 Ceph 会使用 `osd_deep_scrub_interval` 全局配置参数。

```bash
[root@serverc ~]# ceph osd pool set testpool scrub_min_interval 10000
set pool 6 scrub_min_interval to 10000
[root@serverc ~]# ceph osd pool get testpool scrub_min_interval
scrub_min_interval: 10000
```

# 对集群和客户端进行故障排除

## 识别问题

在对 Ceph 问题进行故障排除时，第一步要确定是哪个 Ceph 组件造成了问题。有时，您可以在 `ceph health detail` 或 `ceph health status` 命令提供的信息中找到这一组件

以下故障排除检查清单推荐了后续步骤：

- 确定导致问题的 Ceph 组件。

- 为确定的组件设置调试日志并查看日志。

- 验证您的配置受到支持。

- 确定操作是速度缓慢还是卡滞不动。

## 集群运行状况故障排除

当运行状况检查失败时，集群运行状况会变为 `HEALTH_WARN` 或 `HEALTH_ERR`

`ceph status` 和 `ceph health` 命令可显示集群的运行状况。当集群运行状况为 `HEALTH_WARN` 或 `HEALTH_ERR` 时，可使用 `ceph health detail` 命令来查看运行状况检查消息，以便您可以开始对问题进行故障排除。

```bash
[root@serverc ~]# ceph status
  cluster:
    id:     2ae6d05a-229a-11ec-925e-52540000fa0c
    health: HEALTH_WARN
            1 stray daemon(s) not managed by cephadm
            noscrub,nodeep-scrub flag(s) set
            1 pool(s) do not have an application enabled

  services:
    mon: 4 daemons, quorum serverc.lab.example.com,clienta,serverd,servere (age 70s)
    mgr: serverc.lab.example.com.aiqepd(active, since 3h), standbys: serverd.klrkci, servere.kjwyko, clienta.nncugs
    osd: 11 osds: 10 up (since 51m), 10 in (since 56m)
         flags noscrub,nodeep-scrub
    rgw: 2 daemons active (2 hosts, 1 zones)

  data:
    pools:   6 pools, 137 pgs
    objects: 482 objects, 1.0 GiB
    usage:   3.4 GiB used, 97 GiB / 100 GiB avail
    pgs:     137 active+clean

[root@serverc ~]# ceph health
HEALTH_WARN 1 stray daemon(s) not managed by cephadm; noscrub,nodeep-scrub flag(s) set; 1 pool(s) do not have an application enabled
[root@serverc ~]# ceph health detail
HEALTH_WARN 1 stray daemon(s) not managed by cephadm; noscrub,nodeep-scrub flag(s) set; 1 pool(s) do not have an application enabled
[WRN] CEPHADM_STRAY_DAEMON: 1 stray daemon(s) not managed by cephadm
    stray daemon osd.10 on host clienta.lab.example.com not managed by cephadm
[WRN] OSDMAP_FLAGS: noscrub,nodeep-scrub flag(s) set
[WRN] POOL_APP_NOT_ENABLED: 1 pool(s) do not have an application enabled
    application not enabled on pool 'testpool'
    use 'ceph osd pool application enable <pool-name> <app-name>', where <app-name> is 'cephfs', 'rbd', 'rgw', or freeform for custom applications.
```

## 忽略 Ceph 运行状况警报

已经知道相关警告并且当前不需要修复它们时可以忽略，例如，如果您关闭 OSD 以进行维护，则集群会报告 `HEALTH_WARN` 状态。您可忽略此警告消息，以避免运行状况检查影响报告的整体状态。

要忽略运行状况警报消息，请使用 `ceph health` 命令。

```bash
[root@serverc ~]# ceph health detail
HEALTH_WARN 1 stray daemon(s) not managed by cephadm; noscrub,nodeep-scrub flag(s) set; 1 pool(s) do not have an application enabled
[WRN] CEPHADM_STRAY_DAEMON: 1 stray daemon(s) not managed by cephadm
    stray daemon osd.10 on host clienta.lab.example.com not managed by cephadm
[WRN] OSDMAP_FLAGS: noscrub,nodeep-scrub flag(s) set
[WRN] POOL_APP_NOT_ENABLED: 1 pool(s) do not have an application enabled
    application not enabled on pool 'testpool'
    use 'ceph osd pool application enable <pool-name> <app-name>', where <app-name> is 'cephfs', 'rbd', 'rgw', or freeform for custom applications.
```

忽略一下POOL_APP_NOT_ENABLED这个警告

```bash
[root@serverc ~]# ceph health mute POOL_APP_NOT_ENABLED
[root@serverc ~]# ceph health detail
HEALTH_WARN 1 stray daemon(s) not managed by cephadm; noscrub,nodeep-scrub flag(s) set; (muted: POOL_APP_NOT_ENABLED)
[WRN] CEPHADM_STRAY_DAEMON: 1 stray daemon(s) not managed by cephadm
    stray daemon osd.10 on host clienta.lab.example.com not managed by cephadm
[WRN] OSDMAP_FLAGS: noscrub,nodeep-scrub flag(s) set
(MUTED) [WRN] POOL_APP_NOT_ENABLED: 1 pool(s) do not have an application enabled
    application not enabled on pool 'testpool'
    use 'ceph osd pool application enable <pool-name> <app-name>', where <app-name> is 'cephfs', 'rbd', 'rgw', or freeform for custom applications.
```

当您忽略某条运行状况消息时，如果运行状况<mark>进一步降级</mark>，Ceph 会<mark>自动取消忽略相应警报</mark>。例如，如果您的集群报告一个 OSD 停机，而您将忽略了该警报，则又有 OSD 停机时，Ceph 会自动取消忽略警告。可测量的运行状况警报不可忽略。



## 配置日志记录

可为集群中的每个子系统设置不同的日志记录级别。调试级别的范围为 1 到 20，其中 1 表示简洁，20 表示详细。

Ceph 不会将基于内存的日志发送到输出日志，除非遇到以下情况：

- 引发致命信号。

- 触发代码中的断言。

- 您提出了此要求。

要为输出日志级别和内存级别使用不同的调试级别，需使用斜杠 (/) 字符。例如，`debug_mon = 1/5` 表示将 `ceph-mon` 守护进程的输出日志级别设置为 `1` ，将其内存日志级别设置为 `5`。

### 临时修改

```bash
[root@serverc ~]# ceph tell osd.0 config set debug_ms 1/5
{
    "success": ""
}
[root@serverc ~]# ceph tell osd.0 config get debug_ms
{
    "debug_ms": "1/5"
}

```

### 永久修改

```bash
[root@serverc ~]# ceph config set osd.0 debug_ms 1/5
[root@serverc ~]# ceph config get osd.0 debug_ms
1/5
```

### 设置日志文件轮转

在默认位置 `/var/log/ceph` 下查看 Ceph 日志文件

可通过修改 `/etc/logrotate.d/ceph` 处的日志轮转配置来加快日志轮转。Cron 作业调度程序使用此文件来调度日志轮转。

参考以下例子

```text
rotate 7
weekly
size size
compress
sharedscripts
```

将其放入crontab

```bash
30 * * * * /usr/sbin/logrotate /etc/logrotate.d/ceph >/dev/null 2>&1
```

### 处理 Cephx

默认情况下，所有 Ceph 命令都使用 `client.admin` 用户进行身份验证，但您可以通过使用 `--name` 和 `--id` 选项来指定用户名或用户 ID。

Cephx 的问题通常涉及以下方面：

- 密钥环或 `ceph.conf` 文件权限不正确。

- 缺少密钥环和 `ceph.conf` 文件。

- 给定用户的 `cephx` 权限错误或无效。使用 `ceph auth list` 命令来确定问题。

- 用户名错误或拼写不正确，这也可以使用 `ceph auth list` 命令来验证。



## Ceph监视器故障排除

mon.X 停机（超出仲裁）

如果 Ceph MON 守护进程未在运行，则有错误阻止了守护进程的启动。



时钟偏移

此错误消息表示 MON 的时钟可能没有同步。`mon_clock_drift_allowed` 参数可控制集群在显示警告消息之前允许的最大时钟偏差。



## Ceph OSDs故障处理

以下是最常见的 Ceph OSD 错误消息列表：

full osds

当集群达到 `mon_osd_full_ratio` 参数设置的容量时，Ceph 将返回 `HEALTH_ERR full osds` 消息。默认情况下，此参数设置为 0.95，即集群容量的 95%。

使用 `ceph df` 命令可确定已用原始存储的百分比，由 `%RAW USED` 列给出。如果原始存储的百分比超过 70%，则您可删除不必要的数据，或通过添加新的 OSD 节点来缩减集群。

nearfull osds

当集群达到 `mon_osd_nearfull_ratio` 参数设置的容量时，Ceph 将返回 `nearfull osds` 消息。默认情况下，此参数设置为 0.85，即集群容量的 85%。

出现此警告消息的主要原因有：

- OSD 在集群中的 OSD 节点之间不均衡。

- 根据 OSD 的数量、用例、每个 OSD 的目标 PG 数以及 OSD 使用量，放置组的数量不正确。

- 集群使用了不适当的 CRUSH 可调项。

- OSD 的后端存储几乎已满。

对此问题进行故障排除：

- 验证 PG 数是否足够。

- 验证您是否使用了针对集群版本优化的 CRUSH 可调项；如果没有，则进行调整。

- 根据利用率更改 OSD 的权重。

- 确定 OSD 使用的磁盘上有多少剩余空间。

osds are down

当 OSD 停机或抖动时，Ceph 会返回 `osds are down` 消息。出现此消息的主要原因是由于潜在故障或与其他 OSD 联网问题，其中一个 `ceph-osd` 进程不可用。
